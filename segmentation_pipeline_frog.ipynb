{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import collections\n",
    "import time \n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "train_on_gpu = True\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler, RandomSampler\n",
    "from torch.nn.parallel.data_parallel import data_parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import segmentation_models_pytorch as smp\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations import pytorch as AT\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold \n",
    "\n",
    "# Drawing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 初始设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 文件路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，一个比赛会有如下几个文件/文件夹：  \n",
    "1、train.csv（或类似文件）：该文件一般包括了图片名称和rle信息（run length encode），如果是多标签的话一般也会包含标签的信息；  \n",
    "2、sample_submission.csv（或类似文件）：一个提交格式的样板；  \n",
    "3、train_images（文件夹）：其中包含了所有训练集的图片；  \n",
    "4、test_images（文件夹）：其中包含了所有测试集的图片。  \n",
    "  \n",
    "注意，train与test图片的大小未必是一样的，提交前要注意test的mask尺寸大小如何，这会影响最终的rle编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_FOLDER = '../' # 项目文件夹\n",
    "TRAIN_IMAGES =  PROJ_FOLDER + 'train_images/' # train图片\n",
    "TEST_IMAGES = PROJ_FOLDER + 'test_images/' # test图片\n",
    "train = pd.read_csv(PROJ_FOLDER + 'train.csv') # train.csv\n",
    "sub = pd.read_csv(PROJ_FOLDER + 'sample_submission.csv') # sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = PROJ_FOLDER + 'img_cache/' # 缓存文件夹\n",
    "CACHE_IMG = CACHE + 'image/' # 用于存放压缩后的图片\n",
    "CACHE_MASK = CACHE + 'mask/' # 用于存放压缩后的mask\n",
    "CACHE_SPLIT = CACHE + 'split/' # 用于存放train/valid的分割文件\n",
    "\n",
    "for folder in [CACHE, CACHE_IMG, CACHE_MASK, CACHE_SPLIT]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 csv文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSNAME_TO_CLASSNO={\n",
    "    'Fish'   : 0,\n",
    "    'Flower' : 1,\n",
    "    'Gravel' : 2,\n",
    "    'Sugar'  : 3,\n",
    "} # 类别转数字\n",
    "\n",
    "CLASSNO_TO_CLASSNAME = {v: k for k, v in CLASSNAME_TO_CLASSNO.items()} # 数字转类别\n",
    "NUM_CLASS = len(CLASSNAME_TO_CLASSNO) # 总类别数\n",
    "\n",
    "CLASS_COLOR = [(255,255,0), (0,0,255), (0,255,0), (0,255,255)] # 类别的颜色（用于画图）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.fillna('')\n",
    "df[['image_id', 'class_name']] = df['Image_Label'].str.split('_', expand = True)\n",
    "df['class_no'] = df['class_name'].map(CLASSNAME_TO_CLASSNO)\n",
    "df['encoded_pixel'] = df['EncodedPixels']\n",
    "df['label'] = (df['EncodedPixels'] != '').astype(np.int32)\n",
    "df = df[['image_id', 'class_no', 'class_name', 'label', 'encoded_pixel']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label透视表  (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_df = pd.pivot_table(df, index='image_id', columns='class_name', values='label').reset_index()\n",
    "pvt_df['mix_label'] = (pvt_df['Fish'].astype(str) + pvt_df['Flower'].astype(str) \n",
    "                       + pvt_df['Gravel'].astype(str) + pvt_df['Sugar'].astype(str))\n",
    "pvt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sub.fillna('')\n",
    "test_df[['image_id', 'class_name']] = test_df['Image_Label'].str.split('_', expand = True)\n",
    "test_df['class_no'] = test_df['class_name'].map(CLASSNAME_TO_CLASSNO)\n",
    "test_df['encoded_pixel'] = test_df['EncodedPixels']\n",
    "test_df['label'] = (test_df['EncodedPixels'] != '').astype(np.int32)\n",
    "test_df = test_df[['image_id', 'class_no', 'class_name', 'label', 'encoded_pixel']]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label透视表  (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['encoded_pixel'] = ''\n",
    "test_df['label'] = 0\n",
    "pvt_test_df = pd.pivot_table(test_df, index='image_id', columns='class_name', values='label').reset_index()\n",
    "pvt_test_df['mix_label'] = (pvt_test_df['Fish'].astype(str) + pvt_test_df['Flower'].astype(str)\n",
    "                            + pvt_test_df['Gravel'].astype(str) + pvt_test_df['Sugar'].astype(str))\n",
    "pvt_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 常数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI  = np.pi # pi\n",
    "INF = np.inf #  无穷大\n",
    "EPS = 1e-12 # 防止除以0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_RGB_MEAN = [0.485, 0.456, 0.406] # Imagenet standards\n",
    "IMAGE_RGB_STD  = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = len(df['image_id'].unique()) # train图片数量\n",
    "NUM_TEST = len(test_df['image_id'].unique()) # test图片数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_TO_MASK_SCALE = 0.25 # 图片->mask的缩放系数，此处从1400×2100 -> 350×525\n",
    "MASK_WIDTH = 525\n",
    "MASK_HEIGHT = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_POS = {\n",
    "    'Fish'   : (pvt_df['Fish'].sum(), pvt_df['Fish'].sum()/NUM_TRAIN),\n",
    "    'Flower' : (pvt_df['Flower'].sum(), pvt_df['Flower'].sum()/NUM_TRAIN),\n",
    "    'Gravel' : (pvt_df['Gravel'].sum(), pvt_df['Gravel'].sum()/NUM_TRAIN),\n",
    "    'Sugar'  : (pvt_df['Sugar'].sum(), pvt_df['Sugar'].sum()/NUM_TRAIN),\n",
    "} # train中各标签的数量及其比例\n",
    "\n",
    "NUM_TEST_POS = {\n",
    "    'Fish'   : (1864, 1864/NUM_TEST),\n",
    "    'Flower' : (1508, 1508/NUM_TEST),\n",
    "    'Gravel' : (1982, 1982/NUM_TEST),\n",
    "    'Sugar'  : (2382, 2382/NUM_TEST), \n",
    "} # 根据probe估测的各标签的数量及其比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 随机种子设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 666\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 显卡相关设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1' # 多卡使用 0/1 两张卡\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0' # 使用 0 一张卡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 辅助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 rle相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode(rle, height=350, width=525, fill_value=1):\n",
    "    '''\n",
    "    从rle (string)转为mask\n",
    "    \n",
    "    height: mask高\n",
    "    width: mask宽\n",
    "    '''\n",
    "    mask = np.zeros((height, width), np.float32)\n",
    "    if rle != '':\n",
    "        mask = mask.reshape(-1)\n",
    "        r = [int(r) for r in rle.split(' ')]\n",
    "        r = np.array(r).reshape(-1, 2)\n",
    "        for start, length in r:\n",
    "            start = start - 1  # 1 index\n",
    "            mask[start:(start + length)] = fill_value\n",
    "        mask = mask.reshape(width, height).T\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encode(mask):\n",
    "    '''\n",
    "    从mask转为rle\n",
    "    '''\n",
    "    m = mask.T.flatten()\n",
    "    if m.sum() == 0:\n",
    "        rle = ''\n",
    "    else:\n",
    "        m = np.concatenate([[0], m, [0]])\n",
    "        run = np.where(m[1:] != m[:-1])[0] + 1\n",
    "        run[1::2] -= run[::2]\n",
    "        rle = ' '.join(str(r) for r in run)\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 图片与mask压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dump_image_to_png(input_path, output_path, out_w, out_h):\n",
    "    '''\n",
    "    将图片压缩为更小尺寸的png文件\n",
    "    \n",
    "    input_path: 原图路径\n",
    "    output_path: 新png的保存路径（没有则自动新建文件夹）\n",
    "    out_w: 新png的宽\n",
    "    out_h：新png的高\n",
    "    '''\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    images = os.listdir(input_path)\n",
    "    images.sort()\n",
    "\n",
    "    for image_id in tqdm(images):\n",
    "        print(image_id)\n",
    "        image = cv2.imread(input_path + image_id, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, dsize=(out_w, out_h), interpolation=cv2.INTER_LINEAR)\n",
    "        image_file = output_path + '%s.png'%image_id[:-4] # 去掉末尾的.jpg\n",
    "        cv2.imwrite(image_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dump_mask_to_png(df, output_path, in_w, in_h, out_w, out_h):\n",
    "    '''\n",
    "    提取mask后保存为更小尺寸的png文件\n",
    "    \n",
    "    df: 包含图片名和rle的表（如train）\n",
    "    output_path: 新mask png的保存路径（没有则自动新建文件夹）\n",
    "    in_w: 原图的宽\n",
    "    in_h：原图的高\n",
    "    out_w: 新mask png的宽\n",
    "    out_h：新mask png的高\n",
    "    '''\n",
    "    gb = df.groupby('image_id')\n",
    "    images = list(gb.groups.keys())\n",
    "\n",
    "    for image_id in tqdm(images):\n",
    "        img_info = gb.get_group(image_id).sort_values('class_no') # 某张图片每个标签的详情\n",
    "        assert(len(img_info) == NUM_CLASS)\n",
    "\n",
    "        rle = img_info['encoded_pixel'].values.tolist()\n",
    "        mask = np.array([run_length_decode(r, height=in_h, width=in_w, fill_value=1) for r in rle]) # 包含NUM_CLASS个层\n",
    "\n",
    "        mask = mask.transpose(1, 2, 0) # 变为 h×w×layer\n",
    "        mask = cv2.resize(mask, dsize=(out_w, out_h), interpolation=cv2.INTER_LINEAR) # 变为 h'×w'×layer\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "        mask_file = output_path + '%s.png'%image_id[:-4] # 去掉末尾的.jpg\n",
    "        print(mask_file)\n",
    "        cv2.imwrite(mask_file, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 tensor转图片/mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "    '''tensor转图片'''\n",
    "    image = tensor.data.cpu().numpy()\n",
    "    image = image.transpose(0,2,3,1) # (batch, h, w, layer)\n",
    "    image = image[...,::-1] # 多了一行这个\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_mask(tensor):\n",
    "    '''tensor转mask'''\n",
    "    mask = tensor.data.cpu().numpy()\n",
    "    mask = mask.transpose(0,2,3,1) # (batch, h, w, layer)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 各种增扩函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_flip_lr(image, mask):\n",
    "    '''对图片和对应的mask进行左右翻转'''\n",
    "    image = cv2.flip(image, 1)\n",
    "    mask  = cv2.flip(mask, 1)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_flip_ud(image, mask):\n",
    "    '''对图片和对应的mask进行上下翻转'''\n",
    "    image = cv2.flip(image, 0)\n",
    "    mask = cv2.flip(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_random_crop(image, mask, w, h, mw, mh):\n",
    "    '''\n",
    "    对图片和对应的mask进行随机裁切。\n",
    "    若图片本身尺寸小于w×h，则不裁切。\n",
    "    若大于w×h，则随机裁切一块w×h的区域，对应的mask裁切相应区域，而后将其缩放至mw×mh的大小。\n",
    "    '''\n",
    "    height, width = image.shape[:2]\n",
    "    height_mask, width_mask = mask.shape[:2]\n",
    "    mask = cv2.resize(mask, dsize=(width, height), interpolation=cv2.INTER_LINEAR) # mask缩放至图片大小\n",
    "    \n",
    "    # 若尺寸足够，裁切一块w×h的区域\n",
    "    x, y = 0, 0\n",
    "    if width > w:\n",
    "        x = np.random.choice(width - w)\n",
    "    if height > h:\n",
    "        y = np.random.choice(height - h)\n",
    "    image = image[y:y+h, x:x+w]\n",
    "    mask  = mask [y:y+h, x:x+w]\n",
    "\n",
    "    mask  = cv2.resize(mask, dsize=(mw, mh), interpolation=cv2.INTER_LINEAR)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_random_crop_rescale(image, mask, w, h):\n",
    "    '''\n",
    "    对图片和对应的mask进行随机裁切后分别缩放至图片及mask的原尺寸。\n",
    "    '''\n",
    "    height, width = image.shape[:2]\n",
    "    height_mask, width_mask = mask.shape[:2]\n",
    "    mask = cv2.resize(mask, dsize=(width, height), interpolation=cv2.INTER_LINEAR) # mask缩放至图片大小\n",
    "\n",
    "    x, y= 0, 0\n",
    "    if width > w:\n",
    "        x = np.random.choice(width - w)\n",
    "    if height > h:\n",
    "        y = np.random.choice(height - h)\n",
    "    image = image[y:y+h, x:x+w]\n",
    "    mask = mask[y:y+h, x:x+w]\n",
    "\n",
    "    if (w,h) != (width,height):\n",
    "        image = cv2.resize(image, dsize=(width,height), interpolation=cv2.INTER_LINEAR)\n",
    "        mask  = cv2.resize(mask, dsize=(width_mask, height_mask), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_random_crop_rotate_rescale(image, mask, mode=['rotate','scale','shift']):\n",
    "    '''\n",
    "    对图片和对应的mask进行随机裁切。随后可选择旋转(rotate)、缩放(scale)或是移动(shift)。\n",
    "    再分别缩放至图片及mask的原尺寸。\n",
    "    '''\n",
    "    height, width = image.shape[:2]\n",
    "    height_mask, width_mask = mask.shape[:2]\n",
    "    mask = cv2.resize(mask, dsize=(width,height), interpolation=cv2.INTER_LINEAR) # mask缩放至图片大小\n",
    "\n",
    "    dangle = 0 # 旋转角度\n",
    "    dscale_x, dscale_y = 0, 0 # 缩放系数\n",
    "    dshift_x, dshift_y = 0, 0 # 移动系数\n",
    "\n",
    "    if 'rotate' in mode:\n",
    "        dangle = np.random.uniform(-30, 30) # 随机旋转±30°\n",
    "    if 'scale' in mode:\n",
    "        dscale_x, dscale_y = np.random.uniform(-1, 1, 2)*0.15 # 随机缩放图片长宽的±15% （x, y不同比例）\n",
    "    if 'shift' in mode:\n",
    "        dshift_x, dshift_y = np.random.uniform(-1, 1, 2)*0.10 # 随机移动图片长宽的±10% （x, y不同比例）\n",
    "\n",
    "    cos = np.cos(dangle / 180 * PI)\n",
    "    sin = np.sin(dangle / 180 * PI)\n",
    "    sx, sy = 1 + dscale_x, 1 + dscale_y \n",
    "    tx, ty = dshift_x * width, dshift_y * height\n",
    "\n",
    "    src = np.array([[-width/2,-height/2], [ width/2,-height/2], [ width/2, height/2], [-width/2, height/2]], np.float32)\n",
    "    src = src * [sx,sy]\n",
    "    x = (src * [cos,-sin]).sum(1) + width/2 + tx\n",
    "    y = (src * [sin, cos]).sum(1) + height/2 + ty\n",
    "    src = np.column_stack([x,y])\n",
    "\n",
    "    dst = np.array([[0,0], [width,0], [width, height], [0,height]])\n",
    "    s = src.astype(np.float32)\n",
    "    d = dst.astype(np.float32)\n",
    "    transform = cv2.getPerspectiveTransform(s, d)\n",
    "\n",
    "    image = cv2.warpPerspective(image, transform, (width, height), flags=cv2.INTER_LINEAR, \n",
    "                                borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "    mask = cv2.warpPerspective(mask, transform, (width, height), flags=cv2.INTER_LINEAR, \n",
    "                               borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0,0))\n",
    "    mask = cv2.resize(mask, dsize=(width_mask, height_mask), \n",
    "                      interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    return x * torch.tanh(F.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return mish(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x * F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return swish(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 压缩图片与mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩储存图片\n",
    "run_dump_image_to_png(TRAIN_IMAGES, CACHE_IMG + 'train_1050x700/', 1050, 700)\n",
    "run_dump_image_to_png(TEST_IMAGES, CACHE_IMG + 'test_1050x700/', 1050, 700)\n",
    "\n",
    "# 压缩储存mask\n",
    "run_dump_mask_to_png(df, CACHE_MASK, 2100, 1400, 525, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 分割验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处按照透视表中选择了按照label透视表中的`mix_label`进行分层取样划出3折，方法有待商榷。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=SEED, shuffle=True)\n",
    "for i, (trn_index, val_index) in enumerate(skf.split(pvt_df, pvt_df['mix_label'])):\n",
    "    train_ids = pvt_df['image_id'].iloc[trn_index].values # train \n",
    "    valid_ids = pvt_df['image_id'].iloc[val_index].values # valid\n",
    "    np.save(CACHE_SPLIT + 'train_fold_a%d.npy'%i, train_ids)\n",
    "    np.save(CACHE_SPLIT + 'valid_fold_a%d.npy'%i, valid_ids) # 保存分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样保存一个test的留作后续使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_df['image_id'].unique()\n",
    "np.save(CACHE_SPLIT + 'test.npy', test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 定义Dataset与数据加载方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset主要用于读取数据，并每次输出单个数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset): # 继承自torch的Dataset\n",
    "    '''\n",
    "    一个自定义的Dataset。一个Dataset至少要包括三个函数：\n",
    "    __init__    用于初始化；\n",
    "    __len__     用于定义数据量；\n",
    "    __getitem__ 用于取数据；\n",
    "    \n",
    "    df: label透视表，用于获得每个mask对应的label\n",
    "    split: 分割文件(.npy)的名称\n",
    "    mode: Dataset的类型，指明是'train'还是'test'\n",
    "    augment: 增扩\n",
    "    '''\n",
    "    def __init__(self, df, split, mode='train', augment=None):\n",
    "        '''定义一些内部变量'''\n",
    "        self.df = df\n",
    "        self.split = split\n",
    "        self.mode = mode\n",
    "        self.augment = augment\n",
    "        \n",
    "        if mode == 'train': # train与test对应不同的文件夹\n",
    "            self.folder = CACHE_IMG + 'train_1050x700/' \n",
    "        else:\n",
    "            self.folder = CACHE_IMG + 'test_1050x700/'\n",
    "            \n",
    "        self.img_id = list(np.concatenate([np.load(CACHE_SPLIT + f , allow_pickle=True) for f in split]))\n",
    "        self.num_img = len(self.img_id)\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''定义Dataset的长度'''\n",
    "        return self.num_img\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        '''定义如何取数据'''\n",
    "        image_id = self.img_id[index]\n",
    "        image = cv2.imread('%s%s.png'%(self.folder, image_id[:-4]), cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            mask = cv2.imread(CACHE_MASK + '%s.png'%(image_id[:-4]), cv2.IMREAD_UNCHANGED)\n",
    "        else:\n",
    "            mask_w = MASK_WIDTH\n",
    "            mask_h = MASK_HEIGHT\n",
    "            mask = np.zeros((int(mask_h), int(mask_w), 4), np.uint8)\n",
    "            \n",
    "        image = image.astype(np.float32) / 255\n",
    "        mask = mask.astype(np.float32) / 255\n",
    "        label = self.df.loc[self.df['image_id'] == image_id][list(CLASSNAME_TO_CLASSNO.keys())]\n",
    "        \n",
    "        if self.augment is None:\n",
    "            return image, label, mask, image_id # 可以返回多种内容\n",
    "        else:\n",
    "            return self.augment(image, label, mask, image_id) # 返回图、标签、mask和图名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset中的\\__getitem__定义了每个数据怎么取，而collate_fn定义了每个batch中的单个数据取出来之后有什么批量操作。collate_fn之后将作为DataLoader的参数。以下这个collate_fn仅对每个batch做数据拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_collate(batch):\n",
    "    '''\n",
    "    定义一个collate_fn。Dataset中的__getitem__定义了每个数据怎么取，而collate_fn定义了\n",
    "    每个batch中的单个数据取出来之后有什么批量操作。\n",
    "    \n",
    "    batch: 传入一个batch的数据\n",
    "    '''\n",
    "    batch_size = len(batch) \n",
    "\n",
    "    input_img = [] # 图\n",
    "    truth_label = [] # 标签\n",
    "    truth_mask  = [] # mask，三者与Dataset中的__getitem__的输出一致\n",
    "    img_id = [] # 图名\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        input_img.append(batch[b][0]) # 图\n",
    "        truth_label.append(batch[b][1]) # 标签\n",
    "        truth_mask.append(batch[b][2]) # mask\n",
    "        img_id.append(batch[b][3]) # 图名，顺序与Dataset中的__getitem__的输出一致\n",
    "    \n",
    "    # 拼接图、标签、mask与图名\n",
    "    input_img = np.stack(input_img) # (batch, h, w, layer)\n",
    "    input_img = input_img[...,::-1].copy() # shape不变\n",
    "    input_img = input_img.transpose(0,3,1,2) # (batch, layer， h, w)\n",
    "\n",
    "    truth_mask = np.stack(truth_mask)\n",
    "    truth_mask = truth_mask.transpose(0,3,1,2) # (batch, layer， h, w)\n",
    "\n",
    "    truth_label = np.stack(truth_label)\n",
    "    img_id = np.stack(img_id)\n",
    "\n",
    "    # 转为tensor\n",
    "    input_img = torch.from_numpy(input_img).float()\n",
    "    truth_label = torch.from_numpy(truth_label).float()\n",
    "    truth_mask = torch.from_numpy(truth_mask).float()\n",
    "\n",
    "    # 对batch内的每个图根据mask来标定每个标签是0还是1\n",
    "    if 1:\n",
    "        m = truth_mask.view(batch_size, NUM_CLASS, -1).sum(-1) # (batch, NUM_CLASS)\n",
    "        truth_label = (m > 0).float() # \n",
    "\n",
    "    return input_img, truth_label, truth_mask, img_id # 顺序与Dataset中的__getitem__的输出一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Train的增扩（在线增扩）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augment(image, label, mask, image_id):\n",
    "    '''\n",
    "    该增扩仅针对train，valid与test无需增扩。此外，如果需要全体resize的话，valid与test也要加resize增扩。\n",
    "    参数顺序与Dataset中的__getitem__的输出一致\n",
    "    '''\n",
    "\n",
    "    if np.random.rand() > 0.5: # 50%概率左右翻转\n",
    "        image, mask = do_flip_lr(image, mask)\n",
    "    if np.random.rand() > 0.5: # 50%概率上下翻转\n",
    "        image, mask = do_flip_ud(image, mask)\n",
    "\n",
    "    image, mask = random.choice([\n",
    "        lambda image, mask : (image, mask),\n",
    "        lambda image, mask : do_random_crop_rescale(image, mask, w=925, h=630),\n",
    "        lambda image, mask : do_random_crop_rotate_rescale(image, mask, mode=['rotate']),\n",
    "    ])(image, mask) # 随机选择三种增扩中的一个（第一个是不变）\n",
    "\n",
    "\n",
    "    return image, label, mask, image_id # 顺序与Dataset中的__getitem__的输出一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 创建DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 4\n",
    "batch_size_test = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_dataset = CloudDataset(\n",
    "    df = pvt_df, \n",
    "    split = ['train_fold_a0.npy',],\n",
    "    mode = 'train',\n",
    "    augment = train_augment,\n",
    ")\n",
    "\n",
    "train_loader  = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler = RandomSampler(train_dataset), # 随机采样，指定了sampler，那么shuffle参数必须为False\n",
    "    batch_size = batch_size_train,\n",
    "    drop_last = True, # 如果最后一个batch的数据量小于batch_size，是否抛弃这部分数据\n",
    "    num_workers = 4, # 多线程\n",
    "    pin_memory = True,\n",
    "    collate_fn = null_collate \n",
    ")\n",
    "\n",
    "# Valid\n",
    "valid_dataset = CloudDataset(\n",
    "    df = pvt_df,\n",
    "    split = ['valid_fold_a0.npy',],\n",
    "    mode = 'train',\n",
    "    augment = None,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler = SequentialSampler(valid_dataset), # 顺序采样\n",
    "    batch_size  = batch_size_test,\n",
    "    drop_last   = False,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = null_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为test创建Dataset和DataLoader："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_dataset = CloudDataset(\n",
    "    df = pvt_test_df,\n",
    "    split = ['test.npy',],\n",
    "    mode = 'test',\n",
    "    augment = None,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler = SequentialSampler(test_dataset), # 顺序采样\n",
    "    batch_size  = batch_size_test,\n",
    "    drop_last   = False,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = null_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_dataset = CloudDataset(\n",
    "    df = pvt_df, \n",
    "    split = ['train_fold_a0.npy',],\n",
    "    mode = 'train',\n",
    "    augment = train_augment,\n",
    ")\n",
    "\n",
    "verify_loader  = DataLoader(\n",
    "    verify_dataset,\n",
    "    sampler = RandomSampler(train_dataset), # 随机采样，指定了sampler，那么shuffle参数必须为False\n",
    "    batch_size = batch_size_train,\n",
    "    drop_last = True, # 如果最后一个batch的数据量小于batch_size，是否抛弃这部分数据\n",
    "    num_workers = 4, # 多线程\n",
    "    pin_memory = True,\n",
    "    collate_fn = null_collate \n",
    ")\n",
    "\n",
    "for t, (input_img, truth_label, truth_mask, image_id) in enumerate(verify_loader):\n",
    "    if t < 5:\n",
    "        print('----t=%d---'%t)\n",
    "        print('')\n",
    "        print('input', input_img.shape)\n",
    "        print('truth_label', truth_label.shape)\n",
    "        print('truth_mask ', truth_mask.shape)\n",
    "        print('image_id ', image_id)\n",
    "        print('')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Encoder部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下载预训练权重文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models.resnet34(pretrained=True) # pretrained=True即可下载权重文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN_FILE = '/root/.cache/torch/checkpoints/resnet34-333f7ec4.pth' # 此处输入下载文件时的保存地址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBn2d(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1, stride=1):\n",
    "        super(ConvBn2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, padding=padding, stride=stride, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(out_channel, eps=1e-5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module): # bottleneck type C\n",
    "    def __init__(self, in_channel, channel, out_channel, stride=1, is_shortcut=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.is_shortcut = is_shortcut\n",
    "\n",
    "        self.conv_bn1 = ConvBn2d(in_channel, channel, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv_bn2 = ConvBn2d(channel, out_channel, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        if is_shortcut:\n",
    "            self.shortcut = ConvBn2d(in_channel, out_channel, kernel_size=1, padding=0, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #z = F.relu(self.conv_bn1(x),inplace=True)\n",
    "        z = mish(self.conv_bn1(x))\n",
    "        z = self.conv_bn2(z)\n",
    "\n",
    "        if self.is_shortcut:\n",
    "            x = self.shortcut(x)\n",
    "\n",
    "        z += x\n",
    "        #z = F.relu(z,inplace=True)\n",
    "        z = mish(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class=1000 ):\n",
    "        super(ResNet34, self).__init__()\n",
    "\n",
    "        self.block0  = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, padding=3, stride=2, bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            Mish(),\n",
    "        )\n",
    "        self.block0[0].bias.data.fill_(0.0)\n",
    "\n",
    "        self.block1  = nn.Sequential(\n",
    "             nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n",
    "             BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,),\n",
    "          * [BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,) for i in range(1,3)],\n",
    "        )\n",
    "        self.block2  = nn.Sequential(\n",
    "             BasicBlock( 64,128,128, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(128,128,128, stride=1, is_shortcut=False,) for i in range(1,4)],\n",
    "        )\n",
    "        self.block3  = nn.Sequential(\n",
    "             BasicBlock(128,256,256, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(256,256,256, stride=1, is_shortcut=False,) for i in range(1,6)],\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "             BasicBlock(256,512,512, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(512,512,512, stride=1, is_shortcut=False,) for i in range(1,3)],\n",
    "        )\n",
    "        self.logit = nn.Linear(512,num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "\n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        logit = self.logit(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 加载Encoder权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERSION=[\n",
    " 'block0.0.weight',\t(64, 3, 7, 7),\t 'conv1.weight',\t(64, 3, 7, 7),\n",
    " 'block0.1.weight',\t(64,),\t 'bn1.weight',\t(64,),\n",
    " 'block0.1.bias',\t(64,),\t 'bn1.bias',\t(64,),\n",
    " 'block0.1.running_mean',\t(64,),\t 'bn1.running_mean',\t(64,),\n",
    " 'block0.1.running_var',\t(64,),\t 'bn1.running_var',\t(64,),\n",
    " 'block1.1.conv_bn1.conv.weight',\t(64, 64, 3, 3),\t 'layer1.0.conv1.weight',\t(64, 64, 3, 3),\n",
    " 'block1.1.conv_bn1.bn.weight',\t(64,),\t 'layer1.0.bn1.weight',\t(64,),\n",
    " 'block1.1.conv_bn1.bn.bias',\t(64,),\t 'layer1.0.bn1.bias',\t(64,),\n",
    " 'block1.1.conv_bn1.bn.running_mean',\t(64,),\t 'layer1.0.bn1.running_mean',\t(64,),\n",
    " 'block1.1.conv_bn1.bn.running_var',\t(64,),\t 'layer1.0.bn1.running_var',\t(64,),\n",
    " 'block1.1.conv_bn2.conv.weight',\t(64, 64, 3, 3),\t 'layer1.0.conv2.weight',\t(64, 64, 3, 3),\n",
    " 'block1.1.conv_bn2.bn.weight',\t(64,),\t 'layer1.0.bn2.weight',\t(64,),\n",
    " 'block1.1.conv_bn2.bn.bias',\t(64,),\t 'layer1.0.bn2.bias',\t(64,),\n",
    " 'block1.1.conv_bn2.bn.running_mean',\t(64,),\t 'layer1.0.bn2.running_mean',\t(64,),\n",
    " 'block1.1.conv_bn2.bn.running_var',\t(64,),\t 'layer1.0.bn2.running_var',\t(64,),\n",
    " 'block1.2.conv_bn1.conv.weight',\t(64, 64, 3, 3),\t 'layer1.1.conv1.weight',\t(64, 64, 3, 3),\n",
    " 'block1.2.conv_bn1.bn.weight',\t(64,),\t 'layer1.1.bn1.weight',\t(64,),\n",
    " 'block1.2.conv_bn1.bn.bias',\t(64,),\t 'layer1.1.bn1.bias',\t(64,),\n",
    " 'block1.2.conv_bn1.bn.running_mean',\t(64,),\t 'layer1.1.bn1.running_mean',\t(64,),\n",
    " 'block1.2.conv_bn1.bn.running_var',\t(64,),\t 'layer1.1.bn1.running_var',\t(64,),\n",
    " 'block1.2.conv_bn2.conv.weight',\t(64, 64, 3, 3),\t 'layer1.1.conv2.weight',\t(64, 64, 3, 3),\n",
    " 'block1.2.conv_bn2.bn.weight',\t(64,),\t 'layer1.1.bn2.weight',\t(64,),\n",
    " 'block1.2.conv_bn2.bn.bias',\t(64,),\t 'layer1.1.bn2.bias',\t(64,),\n",
    " 'block1.2.conv_bn2.bn.running_mean',\t(64,),\t 'layer1.1.bn2.running_mean',\t(64,),\n",
    " 'block1.2.conv_bn2.bn.running_var',\t(64,),\t 'layer1.1.bn2.running_var',\t(64,),\n",
    " 'block1.3.conv_bn1.conv.weight',\t(64, 64, 3, 3),\t 'layer1.2.conv1.weight',\t(64, 64, 3, 3),\n",
    " 'block1.3.conv_bn1.bn.weight',\t(64,),\t 'layer1.2.bn1.weight',\t(64,),\n",
    " 'block1.3.conv_bn1.bn.bias',\t(64,),\t 'layer1.2.bn1.bias',\t(64,),\n",
    " 'block1.3.conv_bn1.bn.running_mean',\t(64,),\t 'layer1.2.bn1.running_mean',\t(64,),\n",
    " 'block1.3.conv_bn1.bn.running_var',\t(64,),\t 'layer1.2.bn1.running_var',\t(64,),\n",
    " 'block1.3.conv_bn2.conv.weight',\t(64, 64, 3, 3),\t 'layer1.2.conv2.weight',\t(64, 64, 3, 3),\n",
    " 'block1.3.conv_bn2.bn.weight',\t(64,),\t 'layer1.2.bn2.weight',\t(64,),\n",
    " 'block1.3.conv_bn2.bn.bias',\t(64,),\t 'layer1.2.bn2.bias',\t(64,),\n",
    " 'block1.3.conv_bn2.bn.running_mean',\t(64,),\t 'layer1.2.bn2.running_mean',\t(64,),\n",
    " 'block1.3.conv_bn2.bn.running_var',\t(64,),\t 'layer1.2.bn2.running_var',\t(64,),\n",
    " 'block2.0.conv_bn1.conv.weight',\t(128, 64, 3, 3),\t 'layer2.0.conv1.weight',\t(128, 64, 3, 3),\n",
    " 'block2.0.conv_bn1.bn.weight',\t(128,),\t 'layer2.0.bn1.weight',\t(128,),\n",
    " 'block2.0.conv_bn1.bn.bias',\t(128,),\t 'layer2.0.bn1.bias',\t(128,),\n",
    " 'block2.0.conv_bn1.bn.running_mean',\t(128,),\t 'layer2.0.bn1.running_mean',\t(128,),\n",
    " 'block2.0.conv_bn1.bn.running_var',\t(128,),\t 'layer2.0.bn1.running_var',\t(128,),\n",
    " 'block2.0.conv_bn2.conv.weight',\t(128, 128, 3, 3),\t 'layer2.0.conv2.weight',\t(128, 128, 3, 3),\n",
    " 'block2.0.conv_bn2.bn.weight',\t(128,),\t 'layer2.0.bn2.weight',\t(128,),\n",
    " 'block2.0.conv_bn2.bn.bias',\t(128,),\t 'layer2.0.bn2.bias',\t(128,),\n",
    " 'block2.0.conv_bn2.bn.running_mean',\t(128,),\t 'layer2.0.bn2.running_mean',\t(128,),\n",
    " 'block2.0.conv_bn2.bn.running_var',\t(128,),\t 'layer2.0.bn2.running_var',\t(128,),\n",
    " 'block2.0.shortcut.conv.weight',\t(128, 64, 1, 1),\t 'layer2.0.downsample.0.weight',\t(128, 64, 1, 1),\n",
    " 'block2.0.shortcut.bn.weight',\t(128,),\t 'layer2.0.downsample.1.weight',\t(128,),\n",
    " 'block2.0.shortcut.bn.bias',\t(128,),\t 'layer2.0.downsample.1.bias',\t(128,),\n",
    " 'block2.0.shortcut.bn.running_mean',\t(128,),\t 'layer2.0.downsample.1.running_mean',\t(128,),\n",
    " 'block2.0.shortcut.bn.running_var',\t(128,),\t 'layer2.0.downsample.1.running_var',\t(128,),\n",
    " 'block2.1.conv_bn1.conv.weight',\t(128, 128, 3, 3),\t 'layer2.1.conv1.weight',\t(128, 128, 3, 3),\n",
    " 'block2.1.conv_bn1.bn.weight',\t(128,),\t 'layer2.1.bn1.weight',\t(128,),\n",
    " 'block2.1.conv_bn1.bn.bias',\t(128,),\t 'layer2.1.bn1.bias',\t(128,),\n",
    " 'block2.1.conv_bn1.bn.running_mean',\t(128,),\t 'layer2.1.bn1.running_mean',\t(128,),\n",
    " 'block2.1.conv_bn1.bn.running_var',\t(128,),\t 'layer2.1.bn1.running_var',\t(128,),\n",
    " 'block2.1.conv_bn2.conv.weight',\t(128, 128, 3, 3),\t 'layer2.1.conv2.weight',\t(128, 128, 3, 3),\n",
    " 'block2.1.conv_bn2.bn.weight',\t(128,),\t 'layer2.1.bn2.weight',\t(128,),\n",
    " 'block2.1.conv_bn2.bn.bias',\t(128,),\t 'layer2.1.bn2.bias',\t(128,),\n",
    " 'block2.1.conv_bn2.bn.running_mean',\t(128,),\t 'layer2.1.bn2.running_mean',\t(128,),\n",
    " 'block2.1.conv_bn2.bn.running_var',\t(128,),\t 'layer2.1.bn2.running_var',\t(128,),\n",
    " 'block2.2.conv_bn1.conv.weight',\t(128, 128, 3, 3),\t 'layer2.2.conv1.weight',\t(128, 128, 3, 3),\n",
    " 'block2.2.conv_bn1.bn.weight',\t(128,),\t 'layer2.2.bn1.weight',\t(128,),\n",
    " 'block2.2.conv_bn1.bn.bias',\t(128,),\t 'layer2.2.bn1.bias',\t(128,),\n",
    " 'block2.2.conv_bn1.bn.running_mean',\t(128,),\t 'layer2.2.bn1.running_mean',\t(128,),\n",
    " 'block2.2.conv_bn1.bn.running_var',\t(128,),\t 'layer2.2.bn1.running_var',\t(128,),\n",
    " 'block2.2.conv_bn2.conv.weight',\t(128, 128, 3, 3),\t 'layer2.2.conv2.weight',\t(128, 128, 3, 3),\n",
    " 'block2.2.conv_bn2.bn.weight',\t(128,),\t 'layer2.2.bn2.weight',\t(128,),\n",
    " 'block2.2.conv_bn2.bn.bias',\t(128,),\t 'layer2.2.bn2.bias',\t(128,),\n",
    " 'block2.2.conv_bn2.bn.running_mean',\t(128,),\t 'layer2.2.bn2.running_mean',\t(128,),\n",
    " 'block2.2.conv_bn2.bn.running_var',\t(128,),\t 'layer2.2.bn2.running_var',\t(128,),\n",
    " 'block2.3.conv_bn1.conv.weight',\t(128, 128, 3, 3),\t 'layer2.3.conv1.weight',\t(128, 128, 3, 3),\n",
    " 'block2.3.conv_bn1.bn.weight',\t(128,),\t 'layer2.3.bn1.weight',\t(128,),\n",
    " 'block2.3.conv_bn1.bn.bias',\t(128,),\t 'layer2.3.bn1.bias',\t(128,),\n",
    " 'block2.3.conv_bn1.bn.running_mean',\t(128,),\t 'layer2.3.bn1.running_mean',\t(128,),\n",
    " 'block2.3.conv_bn1.bn.running_var',\t(128,),\t 'layer2.3.bn1.running_var',\t(128,),\n",
    " 'block2.3.conv_bn2.conv.weight',\t(128, 128, 3, 3),\t 'layer2.3.conv2.weight',\t(128, 128, 3, 3),\n",
    " 'block2.3.conv_bn2.bn.weight',\t(128,),\t 'layer2.3.bn2.weight',\t(128,),\n",
    " 'block2.3.conv_bn2.bn.bias',\t(128,),\t 'layer2.3.bn2.bias',\t(128,),\n",
    " 'block2.3.conv_bn2.bn.running_mean',\t(128,),\t 'layer2.3.bn2.running_mean',\t(128,),\n",
    " 'block2.3.conv_bn2.bn.running_var',\t(128,),\t 'layer2.3.bn2.running_var',\t(128,),\n",
    " 'block3.0.conv_bn1.conv.weight',\t(256, 128, 3, 3),\t 'layer3.0.conv1.weight',\t(256, 128, 3, 3),\n",
    " 'block3.0.conv_bn1.bn.weight',\t(256,),\t 'layer3.0.bn1.weight',\t(256,),\n",
    " 'block3.0.conv_bn1.bn.bias',\t(256,),\t 'layer3.0.bn1.bias',\t(256,),\n",
    " 'block3.0.conv_bn1.bn.running_mean',\t(256,),\t 'layer3.0.bn1.running_mean',\t(256,),\n",
    " 'block3.0.conv_bn1.bn.running_var',\t(256,),\t 'layer3.0.bn1.running_var',\t(256,),\n",
    " 'block3.0.conv_bn2.conv.weight',\t(256, 256, 3, 3),\t 'layer3.0.conv2.weight',\t(256, 256, 3, 3),\n",
    " 'block3.0.conv_bn2.bn.weight',\t(256,),\t 'layer3.0.bn2.weight',\t(256,),\n",
    " 'block3.0.conv_bn2.bn.bias',\t(256,),\t 'layer3.0.bn2.bias',\t(256,),\n",
    " 'block3.0.conv_bn2.bn.running_mean',\t(256,),\t 'layer3.0.bn2.running_mean',\t(256,),\n",
    " 'block3.0.conv_bn2.bn.running_var',\t(256,),\t 'layer3.0.bn2.running_var',\t(256,),\n",
    " 'block3.0.shortcut.conv.weight',\t(256, 128, 1, 1),\t 'layer3.0.downsample.0.weight',\t(256, 128, 1, 1),\n",
    " 'block3.0.shortcut.bn.weight',\t(256,),\t 'layer3.0.downsample.1.weight',\t(256,),\n",
    " 'block3.0.shortcut.bn.bias',\t(256,),\t 'layer3.0.downsample.1.bias',\t(256,),\n",
    " 'block3.0.shortcut.bn.running_mean',\t(256,),\t 'layer3.0.downsample.1.running_mean',\t(256,),\n",
    " 'block3.0.shortcut.bn.running_var',\t(256,),\t 'layer3.0.downsample.1.running_var',\t(256,),\n",
    " 'block3.1.conv_bn1.conv.weight',\t(256, 256, 3, 3),\t 'layer3.1.conv1.weight',\t(256, 256, 3, 3),\n",
    " 'block3.1.conv_bn1.bn.weight',\t(256,),\t 'layer3.1.bn1.weight',\t(256,),\n",
    " 'block3.1.conv_bn1.bn.bias',\t(256,),\t 'layer3.1.bn1.bias',\t(256,),\n",
    " 'block3.1.conv_bn1.bn.running_mean',\t(256,),\t 'layer3.1.bn1.running_mean',\t(256,),\n",
    " 'block3.1.conv_bn1.bn.running_var',\t(256,),\t 'layer3.1.bn1.running_var',\t(256,),\n",
    " 'block3.1.conv_bn2.conv.weight',\t(256, 256, 3, 3),\t 'layer3.1.conv2.weight',\t(256, 256, 3, 3),\n",
    " 'block3.1.conv_bn2.bn.weight',\t(256,),\t 'layer3.1.bn2.weight',\t(256,),\n",
    " 'block3.1.conv_bn2.bn.bias',\t(256,),\t 'layer3.1.bn2.bias',\t(256,),\n",
    " 'block3.1.conv_bn2.bn.running_mean',\t(256,),\t 'layer3.1.bn2.running_mean',\t(256,),\n",
    " 'block3.1.conv_bn2.bn.running_var',\t(256,),\t 'layer3.1.bn2.running_var',\t(256,),\n",
    " 'block3.2.conv_bn1.conv.weight',\t(256, 256, 3, 3),\t 'layer3.2.conv1.weight',\t(256, 256, 3, 3),\n",
    " 'block3.2.conv_bn1.bn.weight',\t(256,),\t 'layer3.2.bn1.weight',\t(256,),\n",
    " 'block3.2.conv_bn1.bn.bias',\t(256,),\t 'layer3.2.bn1.bias',\t(256,),\n",
    " 'block3.2.conv_bn1.bn.running_mean',\t(256,),\t 'layer3.2.bn1.running_mean',\t(256,),\n",
    " 'block3.2.conv_bn1.bn.running_var',\t(256,),\t 'layer3.2.bn1.running_var',\t(256,),\n",
    " 'block3.2.conv_bn2.conv.weight',\t(256, 256, 3, 3),\t 'layer3.2.conv2.weight',\t(256, 256, 3, 3),\n",
    " 'block3.2.conv_bn2.bn.weight',\t(256,),\t 'layer3.2.bn2.weight',\t(256,),\n",
    " 'block3.2.conv_bn2.bn.bias',\t(256,),\t 'layer3.2.bn2.bias',\t(256,),\n",
    " 'block3.2.conv_bn2.bn.running_mean',\t(256,),\t 'layer3.2.bn2.running_mean',\t(256,),\n",
    " 'block3.2.conv_bn2.bn.running_var',\t(256,),\t 'layer3.2.bn2.running_var',\t(256,),\n",
    " 'block3.3.conv_bn1.conv.weight',\t(256, 256, 3, 3),\t 'layer3.3.conv1.weight',\t(256, 256, 3, 3),\n",
    " 'block3.3.conv_bn1.bn.weight',\t(256,),\t 'layer3.3.bn1.weight',\t(256,),\n",
    " 'block3.3.conv_bn1.bn.bias',\t(256,),\t 'layer3.3.bn1.bias',\t(256,),\n",
    " 'block3.3.conv_bn1.bn.running_mean',\t(256,),\t 'layer3.3.bn1.running_mean',\t(256,),\n",
    " 'block3.3.conv_bn1.bn.running_var',\t(256,),\t 'layer3.3.bn1.running_var',\t(256,),\n",
    " 'block3.3.conv_bn2.conv.weight',\t(256, 256, 3, 3),\t 'layer3.3.conv2.weight',\t(256, 256, 3, 3),\n",
    " 'block3.3.conv_bn2.bn.weight',\t(256,),\t 'layer3.3.bn2.weight',\t(256,),\n",
    " 'block3.3.conv_bn2.bn.bias',\t(256,),\t 'layer3.3.bn2.bias',\t(256,),\n",
    " 'block3.3.conv_bn2.bn.running_mean',\t(256,),\t 'layer3.3.bn2.running_mean',\t(256,),\n",
    " 'block3.3.conv_bn2.bn.running_var',\t(256,),\t 'layer3.3.bn2.running_var',\t(256,),\n",
    " 'block3.4.conv_bn1.conv.weight',\t(256, 256, 3, 3),\t 'layer3.4.conv1.weight',\t(256, 256, 3, 3),\n",
    " 'block3.4.conv_bn1.bn.weight',\t(256,),\t 'layer3.4.bn1.weight',\t(256,),\n",
    " 'block3.4.conv_bn1.bn.bias',\t(256,),\t 'layer3.4.bn1.bias',\t(256,),\n",
    " 'block3.4.conv_bn1.bn.running_mean',\t(256,),\t 'layer3.4.bn1.running_mean',\t(256,),\n",
    " 'block3.4.conv_bn1.bn.running_var',\t(256,),\t 'layer3.4.bn1.running_var',\t(256,),\n",
    " 'block3.4.conv_bn2.conv.weight',\t(256, 256, 3, 3),\t 'layer3.4.conv2.weight',\t(256, 256, 3, 3),\n",
    " 'block3.4.conv_bn2.bn.weight',\t(256,),\t 'layer3.4.bn2.weight',\t(256,),\n",
    " 'block3.4.conv_bn2.bn.bias',\t(256,),\t 'layer3.4.bn2.bias',\t(256,),\n",
    " 'block3.4.conv_bn2.bn.running_mean',\t(256,),\t 'layer3.4.bn2.running_mean',\t(256,),\n",
    " 'block3.4.conv_bn2.bn.running_var',\t(256,),\t 'layer3.4.bn2.running_var',\t(256,),\n",
    " 'block3.5.conv_bn1.conv.weight',\t(256, 256, 3, 3),\t 'layer3.5.conv1.weight',\t(256, 256, 3, 3),\n",
    " 'block3.5.conv_bn1.bn.weight',\t(256,),\t 'layer3.5.bn1.weight',\t(256,),\n",
    " 'block3.5.conv_bn1.bn.bias',\t(256,),\t 'layer3.5.bn1.bias',\t(256,),\n",
    " 'block3.5.conv_bn1.bn.running_mean',\t(256,),\t 'layer3.5.bn1.running_mean',\t(256,),\n",
    " 'block3.5.conv_bn1.bn.running_var',\t(256,),\t 'layer3.5.bn1.running_var',\t(256,),\n",
    " 'block3.5.conv_bn2.conv.weight',\t(256, 256, 3, 3),\t 'layer3.5.conv2.weight',\t(256, 256, 3, 3),\n",
    " 'block3.5.conv_bn2.bn.weight',\t(256,),\t 'layer3.5.bn2.weight',\t(256,),\n",
    " 'block3.5.conv_bn2.bn.bias',\t(256,),\t 'layer3.5.bn2.bias',\t(256,),\n",
    " 'block3.5.conv_bn2.bn.running_mean',\t(256,),\t 'layer3.5.bn2.running_mean',\t(256,),\n",
    " 'block3.5.conv_bn2.bn.running_var',\t(256,),\t 'layer3.5.bn2.running_var',\t(256,),\n",
    " 'block4.0.conv_bn1.conv.weight',\t(512, 256, 3, 3),\t 'layer4.0.conv1.weight',\t(512, 256, 3, 3),\n",
    " 'block4.0.conv_bn1.bn.weight',\t(512,),\t 'layer4.0.bn1.weight',\t(512,),\n",
    " 'block4.0.conv_bn1.bn.bias',\t(512,),\t 'layer4.0.bn1.bias',\t(512,),\n",
    " 'block4.0.conv_bn1.bn.running_mean',\t(512,),\t 'layer4.0.bn1.running_mean',\t(512,),\n",
    " 'block4.0.conv_bn1.bn.running_var',\t(512,),\t 'layer4.0.bn1.running_var',\t(512,),\n",
    " 'block4.0.conv_bn2.conv.weight',\t(512, 512, 3, 3),\t 'layer4.0.conv2.weight',\t(512, 512, 3, 3),\n",
    " 'block4.0.conv_bn2.bn.weight',\t(512,),\t 'layer4.0.bn2.weight',\t(512,),\n",
    " 'block4.0.conv_bn2.bn.bias',\t(512,),\t 'layer4.0.bn2.bias',\t(512,),\n",
    " 'block4.0.conv_bn2.bn.running_mean',\t(512,),\t 'layer4.0.bn2.running_mean',\t(512,),\n",
    " 'block4.0.conv_bn2.bn.running_var',\t(512,),\t 'layer4.0.bn2.running_var',\t(512,),\n",
    " 'block4.0.shortcut.conv.weight',\t(512, 256, 1, 1),\t 'layer4.0.downsample.0.weight',\t(512, 256, 1, 1),\n",
    " 'block4.0.shortcut.bn.weight',\t(512,),\t 'layer4.0.downsample.1.weight',\t(512,),\n",
    " 'block4.0.shortcut.bn.bias',\t(512,),\t 'layer4.0.downsample.1.bias',\t(512,),\n",
    " 'block4.0.shortcut.bn.running_mean',\t(512,),\t 'layer4.0.downsample.1.running_mean',\t(512,),\n",
    " 'block4.0.shortcut.bn.running_var',\t(512,),\t 'layer4.0.downsample.1.running_var',\t(512,),\n",
    " 'block4.1.conv_bn1.conv.weight',\t(512, 512, 3, 3),\t 'layer4.1.conv1.weight',\t(512, 512, 3, 3),\n",
    " 'block4.1.conv_bn1.bn.weight',\t(512,),\t 'layer4.1.bn1.weight',\t(512,),\n",
    " 'block4.1.conv_bn1.bn.bias',\t(512,),\t 'layer4.1.bn1.bias',\t(512,),\n",
    " 'block4.1.conv_bn1.bn.running_mean',\t(512,),\t 'layer4.1.bn1.running_mean',\t(512,),\n",
    " 'block4.1.conv_bn1.bn.running_var',\t(512,),\t 'layer4.1.bn1.running_var',\t(512,),\n",
    " 'block4.1.conv_bn2.conv.weight',\t(512, 512, 3, 3),\t 'layer4.1.conv2.weight',\t(512, 512, 3, 3),\n",
    " 'block4.1.conv_bn2.bn.weight',\t(512,),\t 'layer4.1.bn2.weight',\t(512,),\n",
    " 'block4.1.conv_bn2.bn.bias',\t(512,),\t 'layer4.1.bn2.bias',\t(512,),\n",
    " 'block4.1.conv_bn2.bn.running_mean',\t(512,),\t 'layer4.1.bn2.running_mean',\t(512,),\n",
    " 'block4.1.conv_bn2.bn.running_var',\t(512,),\t 'layer4.1.bn2.running_var',\t(512,),\n",
    " 'block4.2.conv_bn1.conv.weight',\t(512, 512, 3, 3),\t 'layer4.2.conv1.weight',\t(512, 512, 3, 3),\n",
    " 'block4.2.conv_bn1.bn.weight',\t(512,),\t 'layer4.2.bn1.weight',\t(512,),\n",
    " 'block4.2.conv_bn1.bn.bias',\t(512,),\t 'layer4.2.bn1.bias',\t(512,),\n",
    " 'block4.2.conv_bn1.bn.running_mean',\t(512,),\t 'layer4.2.bn1.running_mean',\t(512,),\n",
    " 'block4.2.conv_bn1.bn.running_var',\t(512,),\t 'layer4.2.bn1.running_var',\t(512,),\n",
    " 'block4.2.conv_bn2.conv.weight',\t(512, 512, 3, 3),\t 'layer4.2.conv2.weight',\t(512, 512, 3, 3),\n",
    " 'block4.2.conv_bn2.bn.weight',\t(512,),\t 'layer4.2.bn2.weight',\t(512,),\n",
    " 'block4.2.conv_bn2.bn.bias',\t(512,),\t 'layer4.2.bn2.bias',\t(512,),\n",
    " 'block4.2.conv_bn2.bn.running_mean',\t(512,),\t 'layer4.2.bn2.running_mean',\t(512,),\n",
    " 'block4.2.conv_bn2.bn.running_var',\t(512,),\t 'layer4.2.bn2.running_var',\t(512,),\n",
    " 'logit.weight',\t(1000, 512),\t 'fc.weight',\t(1000, 512),\n",
    " 'logit.bias',\t(1000,),\t 'fc.bias',\t(1000,),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absorb_rgb_normalisation_to_conv(weight, bias, rgb_mean=IMAGE_RGB_MEAN, rgb_std=IMAGE_RGB_STD ):\n",
    "    '''加载权重时需要调用，作用尚不明确……'''\n",
    "    out, c, h, w = weight.shape\n",
    "    u = torch.from_numpy(np.array(rgb_mean,np.float32).reshape(1,3,1,1)).to(weight.device)\n",
    "    s = torch.from_numpy(np.array(rgb_std ,np.float32).reshape(1,3,1,1)).to(weight.device)\n",
    "\n",
    "    norm_weight = weight/s\n",
    "    norm_bias = -u*weight/s\n",
    "    norm_bias = norm_bias.sum(dim=[1,2,3]) + bias.to(weight.device)\n",
    "\n",
    "    return norm_weight, norm_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrain(net, skip=[], pretrain_file=PRETRAIN_FILE, conversion=CONVERSION, is_print=True):\n",
    "    '''加载预训练权重'''\n",
    "    print('Load pretrain_file: %s'%pretrain_file)\n",
    "\n",
    "    pretrain_state_dict = torch.load(pretrain_file, map_location=lambda storage, loc: storage)\n",
    "    state_dict = net.state_dict()\n",
    "\n",
    "    i = 0\n",
    "    conversion = np.array(conversion, dtype=object).reshape(-1,4)\n",
    "    for key, _ , pretrain_key, _ in conversion:\n",
    "        if any(s in key for s in ['.num_batches_tracked', ] + skip):\n",
    "            continue\n",
    "\n",
    "        if is_print: # 打印信息\n",
    "            print('\\t\\t', '%-48s  %-24s  <---  %-32s  %-24s'%(\n",
    "                key, str(state_dict[key].shape),\n",
    "                pretrain_key, \n",
    "                str(pretrain_state_dict[pretrain_key].shape),\n",
    "            ))\n",
    "        i = i+1\n",
    "\n",
    "        state_dict[key] = pretrain_state_dict[pretrain_key]\n",
    "\n",
    "    if 1:\n",
    "        state_dict['block0.0.weight'], state_dict['block0.0.bias'] =(\n",
    "            absorb_rgb_normalisation_to_conv(state_dict['block0.0.weight'], state_dict['block0.0.bias']))\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "    print('')\n",
    "    print('len(pretrain_state_dict.keys()) = %d'%len(pretrain_state_dict.keys()))\n",
    "    print('len(state_dict.keys()) = %d'%len(state_dict.keys()))\n",
    "    print('loaded = %d'%i)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet34()\n",
    "load_pretrain(net, is_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Decoder部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_like(x, reference, mode='bilinear'):\n",
    "    '''\n",
    "    用于将x缩放成reference同样尺寸（对齐feature map）\n",
    "    '''\n",
    "    if x.shape[2:] !=  reference.shape[2:]:\n",
    "        if mode=='bilinear':\n",
    "            x = F.interpolate(x, size=reference.shape[2:],mode='bilinear',align_corners=False)\n",
    "        if mode=='nearest':\n",
    "            x = F.interpolate(x, size=reference.shape[2:],mode='nearest')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCSEModule(nn.Module):\n",
    "    '''\n",
    "    SCSE Attention模块（spatial/channel sqeeze & excitation）\n",
    "    '''\n",
    "    def __init__(self, ch, re=16):\n",
    "        super().__init__()\n",
    "        self.cSE = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                 nn.Conv2d(ch, ch//re, 1),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(ch//re, ch, 1),\n",
    "                                 nn.Sigmoid()\n",
    "                                )\n",
    "        self.sSE = nn.Sequential(nn.Conv2d(ch, ch, 1),\n",
    "                                 nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.cSE(x) + x * self.sSE(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decode(nn.Module):\n",
    "    def __init__(self, in_channel, channel, out_channel):\n",
    "        super(Decode, self).__init__()\n",
    "        \n",
    "        self.attention1 = SCSEModule(in_channel)\n",
    "        self.attention2 = SCSEModule(out_channel)\n",
    "        \n",
    "        self.top = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, channel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv2d(channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.1),\n",
    "\n",
    "            # nn.Conv2d(out_channel//2, out_channel, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            # BatchNorm2d(out_channel),\n",
    "            # nn.ReLU(inplace=True), #Swish(), #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat(x, 1) # 拼接[xn, resized x]\n",
    "        x = self.attention1(x) # 可以去掉\n",
    "        x = self.top(x)\n",
    "        x = self.attention2(x) # 可以去掉\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 完整模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    Unet作为Architecture，Resnet34作为Backbone\n",
    "    '''\n",
    "    def load_pretrain(self, skip=['logit.'], is_print=True):\n",
    "        '''\n",
    "        加载预训练权重\n",
    "        '''\n",
    "        load_pretrain(self, skip, pretrain_file=PRETRAIN_FILE, conversion=CONVERSION, is_print=is_print)\n",
    "\n",
    "    def __init__(self, num_class=4 ):\n",
    "        super(Net, self).__init__()\n",
    "        e = ResNet34() # 加载Backbone，提取各个组件后丢弃\n",
    "        self.block0 = e.block0\n",
    "        self.block1 = e.block1\n",
    "        self.block2 = e.block2\n",
    "        self.block3 = e.block3\n",
    "        self.block4 = e.block4\n",
    "        e = None  # dropped\n",
    "\n",
    "        self.center= nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ConvBn2d(512, 1024),\n",
    "            nn.ELU(inplace=True),\n",
    "            ConvBn2d(1024, 512),\n",
    "        )\n",
    "\n",
    "        self.decode1 =  Decode(512+512,512,256) # Decode的输入是[xn, resized x]，所以维度翻番\n",
    "        self.decode2 =  Decode(256+256,256,128)\n",
    "        self.decode3 =  Decode(128+128,128, 64)\n",
    "        self.decode4 =  Decode( 64+ 64,128, 64)\n",
    "        self.decode5 =  Decode( 64+ 64, 64, 64)\n",
    "\n",
    "        self.logit = nn.Conv2d(64, num_class, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,C,H,W = x.shape\n",
    "\n",
    "        x0 = self.block0(x)\n",
    "        x1 = self.block1(x0)\n",
    "        x2 = self.block2(x1)\n",
    "        x3 = self.block3(x2)\n",
    "        x4 = self.block4(x3)\n",
    "        \n",
    "        x  = self.center(x4)\n",
    "\n",
    "        x = self.decode1([x4, resize_like(x,x4)])          #; print('d1',x.size())\n",
    "        x = self.decode2([x3, resize_like(x,x3)])          #; print('d2',x.size())\n",
    "        x = self.decode3([x2, resize_like(x,x2)])          #; print('d3',x.size())\n",
    "        x = self.decode4([x1, resize_like(x,x1)])          #; print('d4',x.size())\n",
    "        x = self.decode5([x0, resize_like(x,x0)])          #; print('d5',x.size())\n",
    "\n",
    "        logit = self.logit(x)\n",
    "\n",
    "        probability_mask  = torch.sigmoid(logit)\n",
    "        probability_label = F.adaptive_max_pool2d(probability_mask,1).view(batch_size,-1)\n",
    "        return probability_label, probability_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_check_net():\n",
    "    batch_size = 1\n",
    "    C, H, W = 3, 384, 576\n",
    "\n",
    "    input_img = np.random.uniform(-1, 1, (batch_size,C, H, W ))\n",
    "    input_img = np.random.uniform(-1, 1, (batch_size,C, H, W ))\n",
    "    input_img = torch.from_numpy(input_img).float().cuda()\n",
    "\n",
    "    net = Net().cuda()\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probability_label, probability_mask = net(input_img)\n",
    "\n",
    "    print('')\n",
    "    print('input: ',input_img.shape)\n",
    "    print('probability_label: ',probability_label.shape)\n",
    "    print('probability_mask: ',probability_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_check_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处采用了BCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(probability_label, probability_mask, truth_label, truth_mask):\n",
    "\n",
    "    # label\n",
    "    p = torch.clamp(probability_label, 1e-7, 1-1e-7) # 限制p的范围\n",
    "    t = truth_label\n",
    "    loss_label = - t*torch.log(p) - 2*(1-t)*torch.log(1-p)\n",
    "    loss_label = loss_label.mean()\n",
    "\n",
    "    # mask (此处似乎是多余的)\n",
    "    w = probability_label.detach().view(-1,4,1,1)\n",
    "    p = torch.clamp(probability_mask, 1e-7, 1-1e-7) # 限制p的范围\n",
    "    t = truth_mask\n",
    "\n",
    "    loss_mask = F.binary_cross_entropy(probability_mask, truth_mask, reduction='mean')\n",
    "\n",
    "    return loss_label, loss_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric (probability_label, probability_mask, truth_label, truth_mask, use_reject=True):\n",
    "    '''\n",
    "    probability_label: 各个标签的概率\n",
    "    probability_mask: mask上各个点的概率\n",
    "    truth_label: 实际的标签\n",
    "    truth_mask: 实际的mask\n",
    "    use_reject: mask算出有正像素点的样本是否要求label预测也为正（即同时满足label和mask为正），默认True\n",
    "    '''\n",
    "\n",
    "    threshold_label = 0.50 # 标签概率阈值（大于此为正样本）\n",
    "    threshold_mask = 0.50 # mask各个点的概率阈值（大于此为正样本点）\n",
    "    threshold_size = 1 # mask上图形的最小正像素数量阈值（小于此则定为空mask）\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # label\n",
    "        batch_size, num_class = truth_label.shape\n",
    "\n",
    "        probability = probability_label.view(batch_size, num_class)\n",
    "        truth = truth_label.view(batch_size, num_class)\n",
    "\n",
    "        p = (probability > threshold_label).float() # 预测标签为正的样本，(batch, layer)\n",
    "        t = (truth > 0.5).float() # 实际标签为正的样本\n",
    "        num_tp = t.sum(0) # 正样本的数量\n",
    "        num_tn = batch_size - num_tp # 负样本的数量\n",
    "\n",
    "        tp = ((p + t) == 2).float()  # True positives\n",
    "        tn = ((p + t) == 0).float()  # True negatives\n",
    "        tn = tn.sum(0) # TN数量\n",
    "        tp = tp.sum(0) # TP数量\n",
    "\n",
    "        select = p # 暂存\n",
    "        \n",
    "        # mask\n",
    "        batch_size, num_class, H, W = truth_mask.shape\n",
    "\n",
    "        probability = probability_mask.view(batch_size, num_class, -1) # 每个图层展平，(batch, layer, h×w)\n",
    "        truth = truth_mask.view(batch_size, num_class, -1)\n",
    "\n",
    "        p = (probability > threshold_mask).float() # 预测为正的像素点\n",
    "        t = (truth > 0.5).float() # 实际为正的像素点\n",
    "\n",
    "        t_sum = t.sum(-1) # 每个图，各个layer，实际正像素点的总数 (batch, layer)\n",
    "        p_sum = p.sum(-1) # 每个图，各个layer，预测正像素点的总数 (batch, layer)\n",
    "\n",
    "        neg_index = (t_sum == 0).float() # 实际每个图，哪些layer是空的（一个正像素点都没有）\n",
    "        pos_index = 1 - neg_index # 实际每个图，哪些layer是至少有一个正像素点的\n",
    "\n",
    "        # get subset\n",
    "        if use_reject:\n",
    "            neg_index = neg_index * select # 预测标签为0，或实际mask为空，(batch, layer)\n",
    "            pos_index = pos_index * select # 预测标签为1，且实际mask不为空\n",
    "\n",
    "        num_dn = neg_index.sum(0) # 各个标签的负样本总数\n",
    "        num_dp = pos_index.sum(0) # 各个标签的正样本总数\n",
    "\n",
    "        # 这段后半段逻辑不太明白\n",
    "        dn = (p_sum < threshold_size).float() # 每个图，各个layer，预测mask正像素点的总数小于数量阈值，判为空(batch, layer)\n",
    "        dp = 2 * (p*t).sum(-1) / ((p+t).sum(-1) + EPS) # 通过mask计算dice\n",
    "        dn = (dn * neg_index).sum(0) # mask各种原因判为空，或预测标签为0，或实际mask为空\n",
    "        dp = (dp * pos_index).sum(0) # dice为正，预测标签为1，且实际mask不为空\n",
    "\n",
    "        # 拼接所有metrics\n",
    "        all_metrics = torch.cat([\n",
    "            tn, tp, num_tn, num_tp,\n",
    "            dn, dp, num_dn, num_dp,\n",
    "        ])\n",
    "        all_metrics = all_metrics.data.cpu().numpy().reshape(-1, num_class)\n",
    "        tn, tp, num_tn, num_tp, dn, dp, num_dn, num_dp = all_metrics\n",
    "\n",
    "    return tn, tp, num_tn, num_tp, dn, dp, num_dn, num_dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullScheduler():\n",
    "    '''\n",
    "    固定学习率，默认0.01\n",
    "    '''\n",
    "    def __init__(self, lr=0.01 ):\n",
    "        super(NullScheduler, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.cycle = 0\n",
    "\n",
    "    def __call__(self, time):\n",
    "        return self.lr\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'NullScheduler\\n' + 'lr=%0.5f '%(self.lr)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr):\n",
    "    '''\n",
    "    用于设置optimizer的学习率\n",
    "    '''\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(optimizer):\n",
    "    '''\n",
    "    用于获取optimizer的学习率\n",
    "    '''\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) # 假定只有一个param_group\n",
    "    lr = lr[0]\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 验证 (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_valid(net, valid_loader, out_dir=None):\n",
    "    '''\n",
    "    net: 你的模型\n",
    "    valid_loader: 验证集的DataLoader\n",
    "    out_dir: 用于输出结果，但蛙神把相关代码注释掉了，所以并没有用\n",
    "    '''\n",
    "    valid_loss = np.zeros(2 + 4*NUM_CLASS, np.float32) # 2个loss (label, mask)，每个标签有tn, tp, dn, tp，共计18个\n",
    "    valid_num  = np.zeros_like(valid_loss)\n",
    "\n",
    "    for t, (input_img, truth_label, truth_mask, image_id) in enumerate(valid_loader):\n",
    "        batch_size = len(input_img)\n",
    "\n",
    "        net.eval()\n",
    "        input_img = input_img.cuda()\n",
    "        truth_label = truth_label.cuda()\n",
    "        truth_mask  = truth_mask.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probability_label, probability_mask = data_parallel(net, input_img) # 此处似乎可以自动多卡运行\n",
    "            probability_mask = resize_like(probability_mask, truth_mask, mode='bilinear') # 将mask缩放至图片相同尺寸\n",
    "\n",
    "            loss_label, loss_mask = criterion(probability_label, probability_mask, truth_label, truth_mask)\n",
    "            tn, tp, num_tn, num_tp, dn, dp, num_dn, num_dp = metric(probability_label, probability_mask, \n",
    "                                                                    truth_label, truth_mask)\n",
    "        \n",
    "        l = np.array([loss_label.item()*batch_size, loss_mask.item()*batch_size, *tn, *tp, *dn, *dp ])\n",
    "        n = np.array([batch_size, batch_size, *num_tn, *num_tp, *num_dn, *num_dp])\n",
    "        valid_loss += l\n",
    "        valid_num += n\n",
    "\n",
    "        #==========\n",
    "        #dump results for debug\n",
    "        if 0:\n",
    "            image = tensor_to_image(input_img)\n",
    "            truth_mask = tensor_to_mask(truth_mask)\n",
    "            probability_mask = tensor_to_mask(probability_mask)\n",
    "            truth_label = truth_label.data.cpu().numpy()\n",
    "            probability_label = probability_label.data.cpu().numpy()\n",
    "            \n",
    "            \"\"\"\n",
    "            for b in range(batch_size):\n",
    "                image_id = infor[b].image_id\n",
    "                result = draw_predict_result(\n",
    "                    image[b], truth_label[b], truth_mask[b], probability_label[b], probability_mask[b])\n",
    "\n",
    "                image_show('result',result,resize=0.5)\n",
    "                cv2.imwrite(out_dir +'/valid/%s.png'%image_id[:-4], result)\n",
    "                cv2.waitKey(1)\n",
    "                pass\n",
    "            \"\"\"\n",
    "        #==========\n",
    "\n",
    "        #print(valid_loss)\n",
    "        print('\\r %8d /%d'%(valid_num[0], len(valid_loader.dataset)), end='', flush=True)\n",
    "        pass  #-- end of one data loader --\n",
    "    \n",
    "    assert(valid_num[0] == len(valid_loader.dataset))\n",
    "    valid_loss = valid_loss / (valid_num+1e-8) # 算平均loss\n",
    "\n",
    "    #------\n",
    "    test_pos_ratio = np.array(\n",
    "        [NUM_TEST_POS[c][0]/NUM_TEST for c in list(CLASSNAME_TO_CLASSNO.keys())]\n",
    "    )\n",
    "    test_neg_ratio = 1 - test_pos_ratio # 这是probe推断出的正负样本比例\n",
    "\n",
    "    tn, tp, dn, dp = valid_loss[2:].reshape(-1, NUM_CLASS)\n",
    "    \n",
    "    # 以下这两个指标很迷，理解不能……\n",
    "    kaggle = test_neg_ratio*tn + test_neg_ratio*(1 - tn)*dn + test_pos_ratio*tp*dp\n",
    "    kaggle = kaggle.mean()\n",
    "\n",
    "    kaggle1 = test_neg_ratio*tn + test_pos_ratio*tp\n",
    "    kaggle1 = kaggle1.mean()\n",
    "\n",
    "    return valid_loss, (kaggle, kaggle1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 设置Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存一个Logger用于记录训练的情况，方便比对，也防止万一模型崩了还能留下点信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('torch_training')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger_path = PROJ_FOLDER + 'log/'\n",
    "\n",
    "if not os.path.exists(logger_path):\n",
    "    os.makedirs(logger_path) # 建立log文件夹\n",
    "\n",
    "fh = logging.FileHandler(logger_path + 'local_cv.log')  # 建立log文件\n",
    "fh.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') # 设置log格式\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S') # 时间戳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_str(t, mode='min'):\n",
    "    '''\n",
    "    时间转字符串\n",
    "    '''\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 训练模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置模型保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = PROJ_FOLDER + 'models/' + 'resnet34-unet-fold_a0_attention/'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "炼丹本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    \n",
    "    # 设置初始checkpoint（可以拿训练到一半的模型来继续训练）\n",
    "    initial_checkpoint = None\n",
    "    #initial_checkpoint = '/resnet34-fpn1-fold_a2/checkpoint/00024000_model.pth'\n",
    "    \n",
    "    # 参数设置\n",
    "    scheduler = NullScheduler(lr=0.01) # scheduler选择\n",
    "    iter_accum = 4 # 梯度累积\n",
    "    batch_size = 6\n",
    "\n",
    "    # 初始输出\n",
    "    for f in ['checkpoint', 'train', 'valid']: \n",
    "        os.makedirs(checkpoint_dir + f, exist_ok=True)\n",
    "\n",
    "    logger.info('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n",
    "    logger.info('\\n')\n",
    "    logger.info('\\tSEED         = %u\\n' % SEED)\n",
    "    logger.info('\\tPROJECT_PATH = %s\\n' % PROJECT_PATH)\n",
    "    logger.info('\\tout_dir      = %s\\n' % checkpoint_dir)\n",
    "    logger.info('\\n')\n",
    "\n",
    "\n",
    "    # Dataset\n",
    "    logger.info('** Dataset setting **\\n')\n",
    "    assert(len(train_dataset) >= batch_size)\n",
    "    logger.info('batch_size = %d\\n'%(batch_size))\n",
    "    logger.info('\\n')\n",
    "\n",
    "    # Net \n",
    "    logger.info('** Net setting **\\n')\n",
    "    net = Net().cuda()\n",
    "    logger.info('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n",
    "\n",
    "    if initial_checkpoint is not None: # 不为空就载入模型的参数\n",
    "        state_dict = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n",
    "        net.load_state_dict(state_dict,strict=True)\n",
    "        \n",
    "    else: # 为空则载入预训练参数\n",
    "        net.load_pretrain(is_print=False)\n",
    "\n",
    "    logger.info('net = %s\\n'%(type(net)))\n",
    "    logger.info('\\n')\n",
    "\n",
    "    # optimiser \n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=scheduler(0), \n",
    "                                momentum=0.0, weight_decay=0.0)\n",
    "    #optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=scheduler(0))\n",
    "    #optimizer = torch.optim.RMSprop(net.parameters(), lr =0.0005, alpha = 0.95)\n",
    "\n",
    "    num_iters   = 3000*1000 # 每个epoch共 n/batch_size 个iteration，倒算一共有(num_iters * batch_size / n)个epoch\n",
    "    iter_smooth = 50\n",
    "    iter_log    = 100 # 刷新打印信息和log\n",
    "    iter_valid  = 250 # 更新loss和metrics\n",
    "    iter_save   = [0, num_iters-1] + list(range(0, num_iters, 500)) # 每500个iteration保存一次\n",
    "\n",
    "    start_iter  = 0\n",
    "    start_epoch = 0\n",
    "    rate        = 0\n",
    "    \n",
    "    if initial_checkpoint is not None:\n",
    "        initial_optimizer = initial_checkpoint.replace('_model.pth','_optimizer.pth')\n",
    "        if os.path.exists(initial_optimizer):\n",
    "            checkpoint  = torch.load(initial_optimizer)\n",
    "            start_iter  = checkpoint['iter' ]\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        pass\n",
    "\n",
    "    logger.info('optimizer\\n  %s\\n'%(optimizer))\n",
    "    logger.info('scheduler\\n  %s\\n'%(scheduler))\n",
    "    logger.info('\\n')\n",
    "\n",
    "    ########################### 开始炼丹 ###########################\n",
    "    logger.info('** Start training here! **\\n')\n",
    "    logger.info('   batch_size=%d,  iter_accum=%d\\n'%(batch_size,iter_accum))\n",
    "    logger.info('                    |------------------------------------------------- VALID------------------------------------------------------|---------------------- TRAIN/BATCH -----------------\\n')\n",
    "    logger.info('rate    iter  epoch | kaggle      | loss                tn0,1,2,3 : tp0,1,2,3                     dn0,1,2,3 : dp0,1,2,3           | loss        dn : dp0,1,2,3           | time        \\n')\n",
    "    logger.info('---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n')\n",
    "              #0.00000  28.0* 32.6 | 0.604,0.750 | 0.85,0.29  0.73 0.92 0.83 0.68: 0.54 0.70 0.60 0.84  0.00 0.00 0.00 0.00: 0.53 0.62 0.57 0.64 | 0.00,0.00  0.00: 0.00 0.00 0.00 0.00 | 0 hr 00 min\n",
    "\n",
    "    def message(rate, iters, epoch, kaggle, valid_loss, train_loss, batch_loss, mode='print'):\n",
    "        '''\n",
    "        打印信息\n",
    "        '''\n",
    "        if mode==('print'):\n",
    "            asterisk = ' '\n",
    "            loss = batch_loss\n",
    "        if mode==('log'):\n",
    "            asterisk = '*' if iters in iter_save else ' '\n",
    "            loss = train_loss\n",
    "\n",
    "        text = \\\n",
    "            '%0.5f %5.1f%s %4.1f | '%(rate, iters/1000, asterisk, epoch,) +\\\n",
    "            '%0.3f,%0.3f | '%(*kaggle,) +\\\n",
    "            '%4.2f,%4.2f  %0.2f %0.2f %0.2f %0.2f: %0.2f %0.2f %0.2f %0.2f  %0.2f %0.2f %0.2f %0.2f: %0.2f %0.2f %0.2f %0.2f | '%(*valid_loss,) +\\\n",
    "            '%4.2f,%4.2f  %0.2f: %0.2f %0.2f %0.2f %0.2f |'%(*loss,) +\\\n",
    "            '%s' % (time_to_str((timer() - start_timer),'min'))\n",
    "\n",
    "        return text\n",
    "\n",
    "    #----\n",
    "    kaggle = (0, 0)\n",
    "    valid_loss = np.zeros(18,np.float32)\n",
    "    train_loss = np.zeros( 7,np.float32)\n",
    "    batch_loss = np.zeros_like(valid_loss)\n",
    "    iters = 0\n",
    "    i = 0\n",
    "\n",
    "    start_timer = timer()\n",
    "    while  iters < num_iters: # 只要num_iters没到就会一直训练下去\n",
    "        sum_train_loss = np.zeros_like(train_loss)\n",
    "        sum_train = np.zeros_like(train_loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for t, (input_img, truth_label, truth_mask, image_id) in enumerate(train_loader):\n",
    "            batch_size = len(input_img)\n",
    "            iters  = i + start_iter\n",
    "            epoch = (iters-start_iter) * batch_size / len(train_dataset) + start_epoch\n",
    "\n",
    "            if (iters % iter_valid == 0): # 每iter_valid轮计算一次valid_loss和kaggle\n",
    "                valid_loss, kaggle = do_valid(net, valid_loader, checkpoint_dir) # 最后一个参数暂时没什么意义\n",
    "                pass\n",
    "\n",
    "            if (iters % iter_log == 0): # 每iter_log轮刷新打印信息和log\n",
    "                print('\\r', end='', flush=True)\n",
    "                logger.info(message(rate, iters, epoch, kaggle, valid_loss, train_loss, batch_loss, mode='log'))\n",
    "                logger.info('\\n')\n",
    "\n",
    "            if iters in iter_save: # iter_save轮保存模型\n",
    "                torch.save({\n",
    "                    #'optimizer': optimizer.state_dict(),\n",
    "                    'iter': iters,\n",
    "                    'epoch': epoch, # epoch 0, iters 0 不保存\n",
    "                }, checkpoint_dir +'checkpoint/%08d_optimizer.pth'%(iters))\n",
    "                \n",
    "                if iters != start_iter: \n",
    "                    torch.save(net.state_dict(), checkpoint_dir +'checkpoint/%08d_model.pth'%(iters))\n",
    "                    pass\n",
    "\n",
    "            # 学习率调整 \n",
    "            lr = scheduler(iters)\n",
    "            if lr < 0: \n",
    "                break\n",
    "            adjust_learning_rate(optimizer, lr)\n",
    "            rate = get_learning_rate(optimizer)\n",
    "\n",
    "            # one iteration update  -------------\n",
    "            #net.set_mode('train',is_freeze_bn=True)\n",
    "\n",
    "            net.train()\n",
    "            input_img = input_img.cuda()\n",
    "            truth_label = truth_label.cuda()\n",
    "            truth_mask = truth_mask.cuda()\n",
    "\n",
    "            probability_label, probability_mask = data_parallel(net, input_img)\n",
    "            probability_mask = resize_like(probability_mask, truth_mask, mode='bilinear')\n",
    "\n",
    "            loss_label, loss_mask = criterion(probability_label, probability_mask, truth_label, truth_mask)\n",
    "\n",
    "            ((loss_mask )/iter_accum).backward() # 回传loss\n",
    "            \n",
    "            if (iters % iter_accum) == 0: # 梯度累积\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # 打印信息\n",
    "            tn, tp, num_tn, num_tp, dn, dp, num_dn, num_dp = metric(probability_label, probability_mask, \n",
    "                                                                    truth_label, truth_mask, False) # 注意这里用的False，不是默认的True\n",
    "\n",
    "            l = np.array([loss_label.item()*batch_size, loss_mask.item()*batch_size, dn.sum(), *dp])\n",
    "            n = np.array([batch_size, batch_size, num_dn.sum(), *num_dp ])\n",
    "            batch_loss = l / (n + 1e-8)\n",
    "            sum_train_loss += l\n",
    "            sum_train += n\n",
    "            \n",
    "            if iters%iter_smooth == 0: # 此处不太理解\n",
    "                train_loss = sum_train_loss / (sum_train+EPS)\n",
    "                sum_train_loss[...] = 0\n",
    "                sum_train[...]      = 0\n",
    "\n",
    "            print('\\r', end='', flush=True)\n",
    "            print(message(rate, iters, epoch, kaggle, valid_loss, train_loss, batch_loss, mode='print'), \n",
    "                  end='',flush=True)\n",
    "            i += 1 # 下一个iteration\n",
    "\n",
    "            # debug\n",
    "            if 1:\n",
    "                for di in range(3):\n",
    "                    if (iters+di)%500==0:\n",
    "\n",
    "                        image = tensor_to_image(input_img)\n",
    "                        truth_mask = tensor_to_mask(truth_mask)\n",
    "                        probability_mask = tensor_to_mask(probability_mask)\n",
    "                        truth_label = truth_label.data.cpu().numpy()\n",
    "                        probability_label = probability_label.data.cpu().numpy()\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "    logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 清理显存和内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_evaluate_segmentation(net, test_dataset, augment=[], out_dir=None):\n",
    "    test_num  = 0\n",
    "    test_id   = []\n",
    "    test_probability_label = [] # 8bit\n",
    "    test_probability_mask  = [] # 8bit\n",
    "    test_truth_label = [] # 8bit\n",
    "    test_truth_mask  = [] # 8bit\n",
    "\n",
    "    start_timer = timer()\n",
    "    for t, (input_img, truth_label, truth_mask, image_id) in enumerate(test_loader):\n",
    "\n",
    "        batch_size, C, H, W = input_img.shape\n",
    "        input_img = input_img.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            \n",
    "            # 以下针对测试集增扩，可以将测试集的图片也进行翻转或者旋转，然后将所有增扩的图片概率取平均\n",
    "            # 比如原图1张，左右翻转1张，上下翻转1张，则分别预测后概率取三者平均\n",
    "            num_augment = 0\n",
    "            if 1: # 原图\n",
    "                p_label, p_mask  =  data_parallel(net, input_img)\n",
    "                p_mask = resize_like(p_mask, truth_mask, mode='bilinear')\n",
    "\n",
    "                probability_mask = p_mask\n",
    "                probability_label = p_label\n",
    "                num_augment += 1\n",
    "\n",
    "            if 'flip_lr' in augment:\n",
    "                p_label, p_mask = data_parallel(net, torch.flip(input_img, dims=[3]))\n",
    "                p_mask = resize_like(torch.flip(p_mask, dims=[3]), truth_mask, mode='bilinear')\n",
    "\n",
    "                probability_mask += p_mask\n",
    "                probability_label += p_label\n",
    "                num_augment += 1\n",
    "\n",
    "            if 'flip_ud' in augment:\n",
    "                p_label, p_mask = data_parallel(net, torch.flip(input_img, dims=[2]))\n",
    "                p_mask = resize_like(torch.flip(p_mask, dims=[2]), truth_mask, mode='bilinear')\n",
    "\n",
    "                probability_mask  += p_mask\n",
    "                probability_label += p_label\n",
    "                num_augment+=1\n",
    "\n",
    "            if 'rotate' in augment:\n",
    "                p_label, p_mask   = data_parallel(net, torch.flip(torch.flip(input, dims=[2]), dims=[3]))\n",
    "                p_mask = resize_like(torch.flip(torch.flip(p_mask,dims=[2]), dims=[3]), truth_mask, mode='bilinear')\n",
    "\n",
    "                probability_mask += p_mask\n",
    "                probability_label += p_label\n",
    "                num_augment += 1\n",
    "            \n",
    "            probability_mask  = probability_mask / num_augment\n",
    "            probability_label = probability_label / num_augment\n",
    "\n",
    "        batch_size = len(input_img)\n",
    "        truth_label = truth_label.data.cpu().numpy().astype(np.uint8)\n",
    "        truth_mask = truth_mask.data.cpu().numpy().astype(np.uint8)\n",
    "        probability_mask = (probability_mask.data.cpu().numpy()*255).astype(np.uint8)\n",
    "        probability_label = (probability_label.data.cpu().numpy()*255).astype(np.uint8)\n",
    "\n",
    "        test_id.extend([i for i in image_id])\n",
    "        test_truth_label.append(truth_label)\n",
    "        test_truth_mask.append(truth_mask)\n",
    "        test_probability_label.append(probability_label)\n",
    "        test_probability_mask.append(probability_mask)\n",
    "        test_num += batch_size\n",
    "\n",
    "        print('\\r %4d / %4d  %s'%(\n",
    "             test_num, len(test_loader.dataset), time_to_str((timer() - start_timer), 'min')\n",
    "        ), end='', flush=True)\n",
    "\n",
    "    assert(test_num == len(test_loader.dataset))\n",
    "    print('')\n",
    "\n",
    "    start_timer = timer()\n",
    "    test_truth_label = np.concatenate(test_truth_label)\n",
    "    test_truth_mask  = np.concatenate(test_truth_mask)\n",
    "    test_probability_label = np.concatenate(test_probability_label)\n",
    "    test_probability_mask = np.concatenate(test_probability_mask)\n",
    "    print(time_to_str((timer() - start_timer), 'sec'))\n",
    "\n",
    "    return test_id, test_truth_label, test_truth_mask, test_probability_label, test_probability_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_checkpoint = checkpoint_dir + 'checkpoint/' +'00001000_optimizer.pth'\n",
    "net = Net().cuda()\n",
    "net.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage), strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id, truth_label, truth_mask, probability_label, probability_mask = (\n",
    "    do_evaluate_segmentation(net, test_dataset, augment=['null', 'flip_lr'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各个阈值设定\n",
    "threshold_label = [ 0.50, 0.50, 0.50, 0.50,]\n",
    "threshold_mask  = [ 0.50, 0.50, 0.50, 0.50,]\n",
    "threshold_size  = [ 1, 1, 1, 1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = probability_label > (np.array(threshold_label)*255).astype(np.uint8).reshape(1,4)\n",
    "predict_mask  = probability_mask > (np.array(threshold_mask_pixel)*255).astype(np.uint8).reshape(1,4,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask转成rle\n",
    "image_id_class_id = []\n",
    "encoded_pixel = []\n",
    "for b in range(len(image_id)):\n",
    "    for c in range(NUM_CLASS):\n",
    "        image_id_class_id.append(image_id[b]+'_%s'%(CLASSNO_TO_CLASSNAME[c]))\n",
    "\n",
    "        if predict_label[b,c]==0:\n",
    "            rle=''\n",
    "        else:\n",
    "            rle = run_length_encode(predict_mask[b,c])\n",
    "        encoded_pixel.append(rle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 写提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'sub_'+'_'.join(time.ctime().split(' '))+'.csv'\n",
    "submit = pd.DataFrame(zip(image_id_class_id, encoded_pixel), columns=['Image_Label', 'EncodedPixels'])\n",
    "submit.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
